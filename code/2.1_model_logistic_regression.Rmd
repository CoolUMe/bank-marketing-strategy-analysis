---
title: "logistic_regression"
author: "Yingfan Duan"
date: "2020/11/23"
output: html_document
---

## Preparations

```{r}
# library packages and functions
require(dplyr)
require(readr)
require(caTools)
require(ROSE)
require(pROC)     
source('funcs.R', encoding = 'UTF-8')

# read processed dataset
list(load("../data/working/bank.RData"))
```


## Train-test split

```{r}
# # Encoding the target feature as factor
# bank$y <- factor(bank$y, levels = c(0, 1))
# 
# # delete year and duration
# bank <- subset(bank, select = -c(year,duration,month))
dataset_select <- function(bank){
  # Encoding the target feature as factor
  bank$y <- factor(bank$y, levels = c(0, 1))
  
  # delete year and duration
  bank <- subset(bank, select = -c(year,duration,month))
  
  return(bank)
}
dataset <- dataset_select(bank_rffixed)
# Splitting the dataset into the Training set and Test set
training_set = dataset[1:round(nrow(bank)*0.7),]
test_set = dataset[round(nrow(bank)*0.7):nrow(bank),]
```

## Deal with imbalanced train dataset

```{r}
# check whether dependent variable is balanced
table(training_set$y)
prop.table(table(training_set$y))
```


```{r}
# over-sampling minority
data_balanced_over <- ovun.sample(y ~ ., data = training_set, method = "over",N = 2*27125)$data
table(data_balanced_over$y)

# under-sampling majority
data_balanced_under <- ovun.sample(y ~ ., data = training_set, method = "under", N = 2*1603, seed = 1)$data
table(data_balanced_under$y)

# combination of over- and under-sampling
data_balanced_both <- ovun.sample(y ~ ., data = training_set, method = "both", seed = 123)$data
table(data_balanced_both$y)

# SMOTE
data_balanced_smote <- ROSE(y ~ ., data = training_set, seed = 123)$data
table(data_balanced_smote$y)
```


## logistic regression
```{r}
# Fitting Logistic Regression to the Training set and compare sampling method
sample_compare <- function(training_set, test_set){
  classifier <- glm(formula = y ~ .,
               family = binomial,
               data = training_set)
  prob_pred <- predict(classifier, type = 'response', newdata = test_set[-18])
  y_pred <- ifelse(prob_pred > 0.5, 1, 0)
  result <- evaluation(test_set$y, y_pred)
  return(result)
}

sample_compare(data_balanced_over, test_set)
sample_compare(data_balanced_under, test_set)
sample_compare(data_balanced_both, test_set)
sample_compare(data_balanced_smote, test_set)
```

Accoring to F1 score, under sampling is the best and over sampling is the second best. However, under sampling wastes the majority of the sample. So we go with over sampling. 
```{r}
# use over sampling method
training_set <- data_balanced_over
classifier <- glm(formula = y ~ .,
               family = binomial,
               data = training_set)
summary(classifier)
```

## AIC-based selection
```{r}
opt_step_aic <- step(classifier, direction = "both")
summary(opt_step_aic)


```
conclusion: delete job,education,loan,previous, BIC minimal

## BIC-based selection
```{r}
# AIC=-2*L+k*npar,其中L是对数似然性,npar是拟合模型中的参数个数,而对于AIC严格来说k = 2.
# BIC=-2*L+ log(n)* npar. 即对BIC，有k  = log(n), 其中观察次数为n.以下代码可根据BIC找到最佳模型.

opt_step_bic <- step(classifier, direction = "both", k = log(nrow(training_set)))
summary(opt_step_bic)
```

## hypothesis test: loglikelihood test
```{r}
anova(opt_step_bic,test="Chisq")
```
housing is not significant accoring to loglikelihood test.

## prediction and evaluation
```{r}
# Predicting the Test set results
prob_pred <- predict(opt_step_bic, type = 'response', newdata = test_set[-18])
y_pred_bic <- ifelse(prob_pred > 0.5, 1, 0)
evaluation(test_set$y, y_pred_bic)
# plot(test_set$y, y_pred)


# full model 
prob_pred <- predict(classifier, type = 'response', newdata = test_set[-18])
y_pred_full <- ifelse(prob_pred > 0.5, 1, 0)
evaluation(test_set$y, y_pred_full)

# aic
prob_pred <- predict(opt_step_aic, type = 'response', newdata = test_set[-18])
y_pred_aic <- ifelse(prob_pred > 0.5, 1, 0)
evaluation(test_set$y, y_pred_aic)

# bic confusion matrix
cm <- confusionMatrix(factor(y_pred_bic,levels = c(0, 1)), 
                      factor(test_set$y,levels = c(0, 1)))$table
```

## ROC curve
```{r}
modelroc <- roc(test_set$y,bic_pred_prob, plot = TRUE)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE,
     auc.polygon.col="skyblue", print.thres=TRUE, )

# pred <- prediction(y_pred,test_set$y)
# perf <- performance(pred,"tpr","fpr")
# plot(perf,colorize=TRUE)
```
